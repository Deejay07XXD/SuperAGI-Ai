{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ScXAc8nW4w"
      },
      "source": [
        "## Instructions\n",
        "* No need to read the Setup Section\n",
        "* Go to runtime > Change Runtime Type and set it to use a GPU\n",
        "* Read and run notebook up until the start of the section \"Actual Code!\". Then go to the template notebook and try coding up the model yourself!\n",
        "    * Bonus points for doing that without reading the solutions, and before I do it in the video!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywy4LvRanW4w"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kNfaOeqtnW4x",
        "outputId": "9bf54bba-f095-4c6e-b005-4abbebee7b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-n783tgbf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-n783tgbf\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from easy-transformer==0.1.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.1.0+cu118)\n",
            "Collecting datasets (from easy-transformer==0.1.0)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.5.3)\n",
            "Collecting wandb (from easy-transformer==0.1.0)\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy_einsum (from easy-transformer==0.1.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.4.1)\n",
            "Collecting multiprocess (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easy-transformer==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easy-transformer==0.1.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: easy-transformer\n",
            "  Building wheel for easy-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easy-transformer: filename=easy_transformer-0.1.0-py3-none-any.whl size=55601 sha256=0682990126fcc34601fda5e74bb56af817b56eda6c0f3f29dea9fbebd38b7219\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xuoibhc4/wheels/f0/30/0b/04795723afaae8d7fff47047023153b3e8c47bab26f768cd33\n",
            "Successfully built easy-transformer\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, pyarrow-hotfix, fancy_einsum, einops, docker-pycreds, dill, multiprocess, gitdb, GitPython, wandb, datasets, easy-transformer\n",
            "Successfully installed GitPython-3.1.40 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 easy-transformer-0.1.0 einops-0.7.0 fancy_einsum-0.0.3 gitdb-4.0.11 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n",
            "\n",
            "  \n",
            "  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n",
            "  install Node.js is deprecated now and will eventually be made inactive.\n",
            "\n",
            "  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n",
            "  instructions to migrate your repo.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n",
            "  information about which versions of Node.js and which Linux distributions\n",
            "  are supported and how to install it.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\n",
            "                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n",
            "Continuing in 60 seconds (press Ctrl-C to abort) ...\n",
            "\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,294 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
            "Fetched 4,690 kB in 3s (1,422 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n",
            "Get:4 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,359 B in 2s (3,530 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 0s (56.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 120882 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-ln6o5ygr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-ln6o5ygr\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"Running as a Colab notebook\")\n",
        "  %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "  # Install another version of node that makes PySvelte work way faster\n",
        "  !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "  %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "  %pip install fancy_einsum\n",
        "  %pip install einops\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"Running as a Jupyter notebook - intended for development only!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "llLQgTFcnW4y"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from dataclasses import dataclass\n",
        "from easy_transformer import EasyTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "import tqdm.auto as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v15C9JG3nW4z",
        "outputId": "9d38a303-c11e-4e95-a343-ce5ee6154173",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244,
          "referenced_widgets": [
            "61967fd114df4d62a0484d5ca980ed04",
            "4b7d7436b67a41a4ae5e19a8496d3587",
            "c389ef8d416e4fc690e057968b2385f0",
            "b6b43b6372b14a9794a3e75834af62f1",
            "6656fb5fc35645f18c2d65c9e1985f3e",
            "c12444e5f49e48e5973ae1d2b0d05d96",
            "4d8f255d08cb4bf18fc93c9e445d6cd2",
            "54748e5729804828a8ef2cab3c7b5614",
            "bc15a5c3b3c0426e83db487076f9dcfb",
            "96261808c3d9453db2eb3ec41abe17f1",
            "eb5f480ec75c40d6abf5a25733f676c2",
            "6aaec88d532a4c4cb370c4817dd1f466",
            "f6103836db0f45f6b6b93a28dd6182b1",
            "bc1934d3f25441918f785855e6b9e263",
            "9cab900959e54070a1eac5b7b37eaf08",
            "cc8e7d68c2d1441d925217b8de523cdb",
            "15d7615affdb4a059cced21e2886bf46",
            "2befdfb7b1c5474e8e5cc35be480c69c",
            "fc2880c8e89c436fb7bf3466200a10b5",
            "13f3e2ee89ad4be7b0c8ae41f994c56d",
            "96a706b0c625485c874393ae5d8c5fb5",
            "20d73c09eb5c4fd7b7fb3cba9a3626f5",
            "1c70d783302a44a5b2680245b291cfff",
            "1500ff9f17954d679982bcea1c70512f",
            "efc209d3d67a42e98cac35cdec14d8c0",
            "c82ee813592c46138e327671fff5fc86",
            "859a2e5c8d6e4837a87223f227927445",
            "ca1954bc5acf46598bf0443656066bfe",
            "d1458232fd914d40a661c06724b0ec56",
            "734160c9cd474541837ac775c0b670de",
            "3f572a726cf2454895584ae5e915b880",
            "8a6a9b1a672f456591f725d2a1bc0df4",
            "d58e177ca0c64436bc226b64418617ea",
            "934497e7448f4356a049a546760e3970",
            "b556b8df1ce541ba9fb1b226261a8af1",
            "5f58caaf1e5e4da08510d4f9e1c8d701",
            "493b446daaaa40ca8ed66a6a1d11323a",
            "f5008fba1dff4710ad3c45f5bf452607",
            "f07f13a7a59b4eb0a15181418731f274",
            "12c17c26642d4a3abb26e43fe21c6555",
            "7ced02e309e84e52a04419dda8a3dc53",
            "3745122864f345df90dc69ab2a8a6130",
            "585a99b2c1a148989feb988ba241f4bf",
            "9a0e30c50f9b433fa09d71a090d35fad",
            "613db19804584537b19627866d3f1800",
            "0076e19167564aeb8e23cdbc0144e035",
            "43e7b9e44fd84457a614b4a4b3d81af4",
            "16ffc549b54f4371b6c0dc39868edc36",
            "116a8d93c7194f86820d85abeebe767f",
            "f0eb144921724e9e8b6b06489515d88a",
            "9b8a8b59d87240acb8bb8e333105222d",
            "056de61f68954b72b8cad3b86055b5e4",
            "9ec14a8f30c84f03bdd0346102e32f0e",
            "8f74ef6081ee404db2aa4ce6357fd803",
            "39ab433a78dd4024a32e0a430a5575e9",
            "b7817d85de364a518c0ffe4ce081a87c",
            "8e5dffde591d4a5d9b41b5de5e840c82",
            "602e2e2689224c25badfcb11bc2d0aa3",
            "6119f2b2f2f743cf819f8fb80bbc26ad",
            "1c6d2694e0b346d0891f20badc9e4b89",
            "1ce0b500270f42a199859fa7ed1e274a",
            "5a0ec4f4a623482983b4b79684d4c117",
            "bbf6541354544aeb928422dfc9cdab73",
            "f9b8a185dba74b87aeaec502e69ab273",
            "f8a25e1b777c411ab7c181cd5fe62014",
            "1fb8db38c127427299d0310e5609e1e8"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61967fd114df4d62a0484d5ca980ed04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aaec88d532a4c4cb370c4817dd1f466"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c70d783302a44a5b2680245b291cfff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "934497e7448f4356a049a546760e3970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "613db19804584537b19627866d3f1800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7817d85de364a518c0ffe4ce081a87c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EMxByFyPnW44",
        "outputId": "a941868e-c532-4107-d9ab-507a857b6992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50257])\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"Super Agi\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text)\n",
        "tokens = tokens.cuda()\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBiq7XY4nW44"
      },
      "source": [
        "**Step 3:** Convert the logits to a distribution with a softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a1dZ7iLVnW44",
        "outputId": "4d4f9a0b-75ee-4a15-8b4b-763b33ee9afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50257])\n",
            "torch.Size([1, 4, 50257])\n"
          ]
        }
      ],
      "source": [
        "log_probs = logits.log_softmax(dim=-1)\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm6XFs_QnW44"
      },
      "source": [
        "**Bonus step:** What is the most likely next token at each position?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ow3Dto2JnW44",
        "outputId": "aa392877-df7a-453d-bdfe-0da82b9d502c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<|endoftext|>', '\\n'), ('Super', ' Bowl'), (' Ag', 'ile'), ('i', '\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksIdzFR8nW45"
      },
      "source": [
        "**Step 4:** Map distribution to a token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3amtx1_XnW45",
        "outputId": "144ad4a4-4f3b-4a66-b918-8b7c2485943c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(198, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwX0J-PvnW46"
      },
      "source": [
        "**Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "(More efficient ways to do this, but whatever, doesn't matter conceptually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S2pPUnucnW46",
        "outputId": "df57278a-9b25-4e89-8553-5ad00f5340c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Input: tensor([[50256, 12442,  2449,    72,   198]], device='cuda:0')\n",
            "torch.Size([1, 5])\n",
            "New Input: <|endoftext|>Super Agi\n",
            "\n",
            "torch.Size([1, 5, 50257])\n",
            "tensor(198, device='cuda:0')\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-d982d3e85e6a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n"
          ]
        }
      ],
      "source": [
        "next_tokens = torch.cat([tokens, torch.tensor(next_token, device='cuda', dtype=torch.int64)[None, None]], dim=-1)\n",
        "new_logits = reference_gpt2(next_tokens)\n",
        "print(\"New Input:\", next_tokens)\n",
        "print(next_tokens.shape)\n",
        "print(\"New Input:\", reference_gpt2.tokenizer.decode(next_tokens[0]))\n",
        "\n",
        "print(new_logits.shape)\n",
        "print(new_logits[-1, -1].argmax(-1))\n",
        "\n",
        "print(reference_gpt2.tokenizer.decode(new_logits[-1, -1].argmax(-1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3he1VepnW48"
      },
      "source": [
        "# Actual Code!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOyrVpqsnW49"
      },
      "source": [
        "## Print All Activation Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npvZ221lnW49"
      },
      "source": [
        "Key:\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (4 * d_model)\n",
        "d_head = 64 (d_model / n_heads)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GnSjpX0ZnW4-",
        "outputId": "be954e0e-6f30-4f45-e1d1-1706e474b0d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed torch.Size([1, 4, 768])\n",
            "hook_pos_embed torch.Size([1, 4, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 4, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 4, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 4, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 4, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 4, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 4, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 4, 4])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 4, 4])\n",
            "blocks.0.attn.hook_z torch.Size([1, 4, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 4, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 4, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 4, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 4, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 4, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 4, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 4, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 4, 768])\n",
            "ln_final.hook_scale torch.Size([1, 4, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.cache_dict.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r5YJi_XnW4-"
      },
      "source": [
        "## Print All Parameters Shapes of Reference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s_P9YUywnW4-",
        "outputId": "766d4a53-8419-49e7-cae7-beea24e69150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "blocks.0.ln1.w torch.Size([768])\n",
            "blocks.0.ln1.b torch.Size([768])\n",
            "blocks.0.ln2.w torch.Size([768])\n",
            "blocks.0.ln2.b torch.Size([768])\n",
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n",
            "ln_final.w torch.Size([768])\n",
            "ln_final.b torch.Size([768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL7eVJy4nW4-"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CzExAIeAnW4-",
        "outputId": "d5fdba56-c093-411a-8e76-fbafabe17bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cuda', attention_dir='causal', attn_only=False, seed=42, initializer_range=0.02886751345948129, init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egkGnSu8nW4_"
      },
      "source": [
        "We define a stripped down config for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KQ_55-N0nW4_",
        "outputId": "37272ff4-76cd-40b1-bf0b-0a552d4968e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lSmWm6VnW4_"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG8bEMAonW4_"
      },
      "source": [
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "co2c3c1GnW4_"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    random_input = torch.randn(shape).cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    random_input = torch.randint(100, 1000, shape).cuda()\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).cuda()\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    # Allow inputs of strings or tensors\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)\n",
        "    output = layer(reference_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    reference_output = gpt2_layer(reference_input)\n",
        "    print(\"Reference output shape:\", reference_output.shape)\n",
        "\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh0ogip8nW4_"
      },
      "source": [
        "## LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHrT_PX2nW4_"
      },
      "source": [
        "Make mean 0\n",
        "Normalize to have variance 1\n",
        "Scale with learned weights\n",
        "Translate with learned bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fvqSAaEJnW4_"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual):\n",
        "        # residual: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Residual:\", residual.shape)\n",
        "        residual = residual - einops.reduce(residual, \"batch position d_model -> batch position 1\", \"mean\")\n",
        "        # Calculate the variance, square root it. Add in an epsilon to prevent divide by zero.\n",
        "        scale = (einops.reduce(residual.pow(2), \"batch position d_model -> batch position 1\", \"mean\") + cfg.layer_norm_eps).sqrt()\n",
        "        normalized = residual / scale\n",
        "        normalized = normalized * self.w + self.b\n",
        "        if self.cfg.debug: print(\"Normalized:\", residual.shape)\n",
        "        return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NVgR1z1gnW5A",
        "outputId": "0c278d56-c353-438d-80f4-2b5d00f07435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK42gGUYnW5A"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLrTQWNenW5A"
      },
      "source": [
        "Basically a lookup table from tokens to residual stream vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3N_J7GOQnW5A",
        "outputId": "e8f9e970-59b0-4427-89ed-425a7de10591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4])\n",
            "Tokens: torch.Size([1, 4])\n",
            "Embeddings: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [-0.0687, -0.1477,  0.1556,  ..., -0.0525,  0.0243, -0.2818],\n",
              "         [ 0.1218, -0.1087, -0.0651,  ...,  0.0662,  0.1520,  0.2024],\n",
              "         [ 0.0125, -0.0498,  0.1088,  ...,  0.2399, -0.1205, -0.1070]]],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        embed = self.W_E[tokens, :] # [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Embeddings:\", embed.shape)\n",
        "        return embed\n",
        "\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vui-rDNgnW5A"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xzDXtVX2nW5A",
        "outputId": "3fd8d6a6-b175-4bfa-ff12-4b89cfb429a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4])\n",
            "Tokens: torch.Size([1, 4])\n",
            "pos_embed: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         [-2.8337e-04, -7.3803e-02,  1.0553e-01,  ...,  1.0157e-02,\n",
              "           1.7659e-02, -7.0854e-03]]], device='cuda:0',\n",
              "       grad_fn=<ExpandBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
        "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
        "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
        "        return pos_embed\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class RotaryPositionalEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_len=1024):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.max_len = max_len\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        t = torch.arange(max_len).type_as(inv_freq)\n",
        "        freqs = torch.einsum('i,j->ij', t, inv_freq)\n",
        "        self.register_buffer('sin', freqs.sin())\n",
        "        self.register_buffer('cos', freqs.cos())\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        sin, cos = self.sin[:seq_len, :], self.cos[:seq_len, :]\n",
        "        return torch.stack((x[..., 0::2] * cos + x[..., 1::2] * sin, x[..., 0::2] * sin - x[..., 1::2] * cos), dim=-1).flatten(-2)\n"
      ],
      "metadata": {
        "id": "_wV-p7J_111V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FaRAg6hnW5B"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1rSU1Fl7nW5B",
        "outputId": "0c894154-1f8e-41c5-dd67-f386b78a56b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7966,  0.0170,  0.0348,  ...,  0.0331, -0.0231,  0.1810],\n",
              "         [ 0.7651, -0.1799, -0.6978,  ...,  0.0304, -0.0038,  0.0824],\n",
              "         [ 1.4731, -0.5763, -0.0987,  ...,  0.0158, -0.0442,  0.1607],\n",
              "         [ 2.1509, -0.4782, -0.1073,  ...,  0.0399, -0.0573, -0.0055]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32, device=\"cuda\"))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_pre:\", normalized_resid_pre.shape)\n",
        "\n",
        "        q = einsum(\"batch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\", normalized_resid_pre, self.W_Q) + self.b_Q\n",
        "        k = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_K) + self.b_K\n",
        "\n",
        "        attn_scores = einsum(\"batch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\", q, k)\n",
        "        attn_scores = attn_scores / math.sqrt(self.cfg.d_head)\n",
        "        attn_scores = self.apply_causal_mask(attn_scores)\n",
        "\n",
        "        pattern = attn_scores.softmax(dim=-1) # [batch, n_head, query_pos, key_pos]\n",
        "\n",
        "        v = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_V) + self.b_V\n",
        "\n",
        "        z = einsum(\"batch n_heads query_pos key_pos, batch key_pos n_heads d_head -> batch query_pos n_heads d_head\", pattern, v)\n",
        "\n",
        "        attn_out = einsum(\"batch query_pos n_heads d_head, n_heads d_head d_model -> batch query_pos d_model\", z, self.W_O) + self.b_O\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
        "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size,heads):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size // heads\n",
        "\n",
        "        assert (\n",
        "            self.head_dim * heads == embed_size\n",
        "        ), \"Embedding size should be divisible by heads\"\n",
        "\n",
        "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
        "\n",
        "    def apply_rotary_embedding(self, q, k, rotary_pos_emb):\n",
        "        # Apply rotary positional embeddings to query and key\n",
        "        q_rot = rotary_pos_emb(q)\n",
        "        k_rot = rotary_pos_emb(k)\n",
        "        return q_rot, k_rot\n",
        "\n",
        "    def forward(self, values, keys, query, mask, rotary_pos_emb):\n",
        "        N = query.shape[0]\n",
        "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
        "\n",
        "        # Split the embedding into self.heads different pieces\n",
        "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
        "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
        "        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n",
        "\n",
        "        values = self.values(values)\n",
        "        keys = self.keys(keys)\n",
        "        queries = self.queries(queries)\n",
        "\n",
        "        # Applying Rotary Positional Embeddings\n",
        "        queries, keys = self.apply_rotary_embedding(queries, keys, rotary_pos_emb)\n",
        "\n",
        "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys]) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        attention = torch.nn.functional.softmax(energy, dim=3)\n",
        "\n",
        "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
        "            N, query_len, self.heads * self.head_dim\n",
        "        )\n",
        "\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "K4Dlul0l7CUk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyRotaryEmbedding(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x  # Simply return the input as-is\n",
        "def rand_float_test2(layer_class, embed_size, heads, input_shape):\n",
        "    layer = layer_class(embed_size, heads)\n",
        "    x = torch.rand(input_shape)\n",
        "    mask = torch.randint(0, 2, (input_shape[0], 1, 1, input_shape[1]))\n",
        "    dummy_rotary_emb = DummyRotaryEmbedding()  # Create a dummy rotary embedding instance\n",
        "    output = layer(x, x, x, mask, dummy_rotary_emb)  # Pass the dummy rotary embedding\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "# Example usage\n",
        "embed_size = 768  # Set this to your model's embedding size\n",
        "num_heads = 12    # Set this to the number of heads in your attention layer\n",
        "rand_float_test2(SelfAttention, embed_size, num_heads, [2, 4, 768])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaKmDT2qCMc_",
        "outputId": "f4e77487-2297-4619-8aa2-3384cf304959"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyRotaryEmbedding(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x  # Simply return the input as-is\n",
        "\n",
        "def load_gpt2_test2(custom_layer_class, gpt2_layer, input_tensor):\n",
        "    custom_layer = custom_layer_class(*input_tensor.shape)\n",
        "\n",
        "    # Create a dummy rotary embedding instance\n",
        "    dummy_rotary_emb = DummyRotaryEmbedding()\n",
        "\n",
        "    # Copy weights from GPT-2 layer to custom layer\n",
        "    custom_layer.load_state_dict(gpt2_layer.state_dict())\n",
        "\n",
        "    # Forward pass through GPT-2 layer and custom layer\n",
        "    with torch.no_grad():\n",
        "        gpt2_output = gpt2_layer(input_tensor, input_tensor, input_tensor, None)\n",
        "        custom_output = custom_layer(input_tensor, input_tensor, input_tensor, None, dummy_rotary_emb)\n",
        "\n",
        "    # Compare outputs\n",
        "    print(f\"Are the outputs close? {torch.allclose(gpt2_output, custom_output, atol=1e-5)}\")\n",
        "\n",
        "# Example usage\n",
        "# Ensure 'reference_gpt2' is your pre-loaded GPT-2 model and 'cache' is appropriately defined\n",
        "load_gpt2_test2(SelfAttention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "7V56-Xcj8SRB",
        "outputId": "2c306119-a20e-4416-996a-a4e37cbb79a3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-3c708cb643a0>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Ensure 'reference_gpt2' is your pre-loaded GPT-2 model and 'cache' is appropriately defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mload_gpt2_test2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSelfAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_gpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"blocks.0.ln1.hook_normalized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-3c708cb643a0>\u001b[0m in \u001b[0;36mload_gpt2_test2\u001b[0;34m(custom_layer_class, gpt2_layer, input_tensor)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_gpt2_test2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_layer_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpt2_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcustom_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_layer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create a dummy rotary embedding instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SelfAttention.__init__() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvB7tA3wnW5B"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UP5k5-2enW5B",
        "outputId": "6299079f-b9c6-4fcf-b724-fb368fb34f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.4380,  0.3624,  0.5117,  ...,  1.7227,  1.5761,  0.0368],\n",
              "         [ 1.4700, -0.6963, -0.1730,  ..., -0.7445, -0.4208, -1.4970],\n",
              "         [-0.5696, -0.8485,  0.6953,  ..., -2.8522, -1.3283,  2.7482],\n",
              "         [-0.7392, -0.2214, -0.8621,  ..., -1.4895, -0.4074,  1.3895]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "    def forward(self, normalized_resid_mid):\n",
        "        # normalized_resid_mid: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_mid:\", normalized_resid_mid.shape)\n",
        "        pre = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = einsum(\"batch position d_mlp, d_mlp d_model -> batch position d_model\", post, self.W_out) + self.b_out\n",
        "        return mlp_out\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPq7JwMAnW5C"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xBmD740DnW5C",
        "outputId": "b2b7ab81-443c-40b5-d8c6-74d2222c8b04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 768])\n",
            "Reference output shape: torch.Size([1, 4, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3911,  0.1543,  0.6005,  ...,  1.7198,  1.7365,  0.3930],\n",
              "         [ 2.1903, -1.0777, -0.8100,  ..., -0.7324, -0.3901, -1.6965],\n",
              "         [ 1.0295, -1.6183,  0.5861,  ..., -2.7505, -1.2011,  3.0899],\n",
              "         [ 1.4239, -0.8232, -0.7551,  ..., -1.1995, -0.5675,  1.2700]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        normalized_resid_pre = self.ln1(resid_pre)\n",
        "        attn_out = self.attn(normalized_resid_pre)\n",
        "        resid_mid = resid_pre + attn_out\n",
        "\n",
        "        normalized_resid_mid = self.ln2(resid_mid)\n",
        "        mlp_out = self.mlp(normalized_resid_mid)\n",
        "        resid_post = resid_mid + mlp_out\n",
        "        return resid_post\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_3YccabnW5C"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ipohgg5TnW5C",
        "outputId": "35c2cf67-0a83-4cdb-da65-92f6840d76ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 4, 768])\n",
            "Normalized_resid_final: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 50257])\n",
            "Reference output shape: torch.Size([1, 4, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-43.4317, -39.8364, -43.0659,  ..., -54.0877, -54.3451, -42.3644],\n",
              "         [-53.0146, -53.7350, -56.7932,  ..., -60.5973, -61.5323, -54.6270],\n",
              "         [-66.3314, -68.2656, -70.6114,  ..., -79.3397, -75.8246, -67.9283],\n",
              "         [-69.4183, -72.4175, -74.1232,  ..., -80.7086, -78.8362, -70.9239]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_final:\", normalized_resid_final.shape)\n",
        "        logits = einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
        "        return logits\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ0Z2hFSnW5C"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "BX2qcW6rnW5C",
        "outputId": "3689b2bc-f30d-422e-f6f9-ad1e1d0ee9bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 4])\n",
            "Tokens: torch.Size([1, 4])\n",
            "Embeddings: torch.Size([1, 4, 768])\n",
            "Tokens: torch.Size([1, 4])\n",
            "pos_embed: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 4, 768])\n",
            "Residual: torch.Size([1, 4, 768])\n",
            "Normalized: torch.Size([1, 4, 768])\n",
            "Normalized_resid_final: torch.Size([1, 4, 768])\n",
            "Output shape: torch.Size([1, 4, 50257])\n",
            "Reference output shape: torch.Size([1, 4, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-43.4317, -39.8364, -43.0659,  ..., -54.0877, -54.3451, -42.3644],\n",
              "         [-53.0146, -53.7350, -56.7932,  ..., -60.5972, -61.5323, -54.6270],\n",
              "         [-66.3314, -68.2656, -70.6114,  ..., -79.3397, -75.8246, -67.9283],\n",
              "         [-69.4183, -72.4175, -74.1232,  ..., -80.7086, -78.8362, -70.9239]]],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "        embed = self.embed(tokens)\n",
        "        pos_embed = self.pos_embed(tokens)\n",
        "        residual = embed + pos_embed\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        normalized_resid_final = self.ln_final(residual)\n",
        "        logits = self.unembed(normalized_resid_final)\n",
        "        # logits have shape [batch, position, logits]\n",
        "        return logits\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=768, num_heads=12, num_layers=12, ff_hidden=3072):\n",
        "        super(DemoTransformer, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.rotary_embedding = RotaryPositionalEmbedding(embed_size)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.fc = nn.Linear(embed_size, vocab_size)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "    # tokens [batch, position]\n",
        "      embed = self.embed(tokens)\n",
        "\n",
        "    # Apply Rotary Positional Embeddings instead of traditional pos_embed\n",
        "    # Assume that self.rotary_embedding is an instance of your RotaryPositionalEmbedding class\n",
        "      rotary_pos_embed = self.rotary_embedding(embed)  # This assumes that embed has shape [batch, position, embed_size]\n",
        "\n",
        "    # The rest of the forward pass remains the same\n",
        "      for block in self.blocks:\n",
        "        rotary_pos_embed = block(rotary_pos_embed)\n",
        "      normalized_resid_final = self.ln_final(rotary_pos_embed)\n",
        "      logits = self.unembed(normalized_resid_final)\n",
        "    # logits have shape [batch, position, logits]\n",
        "      return logits\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Z8T6h3nW5D"
      },
      "source": [
        "# Try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "JwHFIyz7nW5D",
        "outputId": "47386a98-1218-4448-c6cf-aaaee8d65157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DemoTransformer(\n",
              "  (embed): Embed()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x TransformerBlock(\n",
              "      (ln1): LayerNorm()\n",
              "      (attn): Attention()\n",
              "      (ln2): LayerNorm()\n",
              "      (mlp): MLP()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm()\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "demo_gpt2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAgAx23TnW5D"
      },
      "source": [
        "Take a test string - the intro paragraph of today's featured Wikipedia article. Let's calculate the loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gwh9ySGTnW5D"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Is this the real life\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "STiNOIxhnW5D"
      },
      "outputs": [],
      "source": [
        "test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "demo_logits = demo_gpt2(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ibc-37V9nW5D",
        "outputId": "7f84279e-3165-440a-f410-0fc6175cfbee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.8748, device='cuda:0', grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0208, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(48.1716, device='cuda:0', grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Measure next token loss\n",
        "    # Logits have shape [batch, position, d_vocab]\n",
        "    # Tokens have shape [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob\", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCiRi3RmnW5D"
      },
      "source": [
        "We can also greedily generate text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tMsNNr99nW5D",
        "outputId": "93e73e51-e014-4f87-a924-e84d9a6f3f29",
        "colab": {
          "referenced_widgets": [
            "f9a4166547884e6b9847ff004ce8b322",
            "de12a8aa21b74319aa627463324082fb",
            "2f1820f3b84c4824898f01eabbddddc3",
            "c3123af8d4d44ed1ba9c6fa18950bf06",
            "d1f7c53d8a934564b4af06b979e93bd5",
            "4e4f2d0981a648d4a4494ecc712c9a1f",
            "ce63efcda42f4087a69706083adf82f8",
            "d3282e79feef4817b93800c4b04bf427",
            "79c09fcc9b1345ffa097e51b1ab03452",
            "708466e0ba514ee49136c55c9dddc59d",
            "3dcc9f21d39e49b3a81a14c85d692689"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9a4166547884e6b9847ff004ce8b322"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SuperAgi campus requirtment is competetive.\n",
            "\n",
            "\n",
            "The requirtment is a form of academic support for students who are not able to attend the school. The requirtment is not a substitute for a full-time job.\n",
            "\n",
            "\n",
            "The requirtment is not a substitute for a full-time job.\n",
            "\n",
            "\n",
            "The requirtment is not a substitute for a full-time job.\n",
            "\n",
            "\n",
            "The requirtment is not a substitute for a full-time job.\n",
            "\n",
            "\n",
            "The requirtment is not a\n"
          ]
        }
      ],
      "source": [
        "test_string = \"SuperAgi campus requirtment is competetive\"\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).cuda()\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "print(test_string)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61967fd114df4d62a0484d5ca980ed04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b7d7436b67a41a4ae5e19a8496d3587",
              "IPY_MODEL_c389ef8d416e4fc690e057968b2385f0",
              "IPY_MODEL_b6b43b6372b14a9794a3e75834af62f1"
            ],
            "layout": "IPY_MODEL_6656fb5fc35645f18c2d65c9e1985f3e"
          }
        },
        "4b7d7436b67a41a4ae5e19a8496d3587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c12444e5f49e48e5973ae1d2b0d05d96",
            "placeholder": "​",
            "style": "IPY_MODEL_4d8f255d08cb4bf18fc93c9e445d6cd2",
            "value": "config.json: 100%"
          }
        },
        "c389ef8d416e4fc690e057968b2385f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54748e5729804828a8ef2cab3c7b5614",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc15a5c3b3c0426e83db487076f9dcfb",
            "value": 665
          }
        },
        "b6b43b6372b14a9794a3e75834af62f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96261808c3d9453db2eb3ec41abe17f1",
            "placeholder": "​",
            "style": "IPY_MODEL_eb5f480ec75c40d6abf5a25733f676c2",
            "value": " 665/665 [00:00&lt;00:00, 38.2kB/s]"
          }
        },
        "6656fb5fc35645f18c2d65c9e1985f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12444e5f49e48e5973ae1d2b0d05d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8f255d08cb4bf18fc93c9e445d6cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54748e5729804828a8ef2cab3c7b5614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc15a5c3b3c0426e83db487076f9dcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96261808c3d9453db2eb3ec41abe17f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5f480ec75c40d6abf5a25733f676c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aaec88d532a4c4cb370c4817dd1f466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6103836db0f45f6b6b93a28dd6182b1",
              "IPY_MODEL_bc1934d3f25441918f785855e6b9e263",
              "IPY_MODEL_9cab900959e54070a1eac5b7b37eaf08"
            ],
            "layout": "IPY_MODEL_cc8e7d68c2d1441d925217b8de523cdb"
          }
        },
        "f6103836db0f45f6b6b93a28dd6182b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15d7615affdb4a059cced21e2886bf46",
            "placeholder": "​",
            "style": "IPY_MODEL_2befdfb7b1c5474e8e5cc35be480c69c",
            "value": "model.safetensors: 100%"
          }
        },
        "bc1934d3f25441918f785855e6b9e263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc2880c8e89c436fb7bf3466200a10b5",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13f3e2ee89ad4be7b0c8ae41f994c56d",
            "value": 548105171
          }
        },
        "9cab900959e54070a1eac5b7b37eaf08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a706b0c625485c874393ae5d8c5fb5",
            "placeholder": "​",
            "style": "IPY_MODEL_20d73c09eb5c4fd7b7fb3cba9a3626f5",
            "value": " 548M/548M [00:02&lt;00:00, 234MB/s]"
          }
        },
        "cc8e7d68c2d1441d925217b8de523cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d7615affdb4a059cced21e2886bf46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2befdfb7b1c5474e8e5cc35be480c69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc2880c8e89c436fb7bf3466200a10b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f3e2ee89ad4be7b0c8ae41f994c56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96a706b0c625485c874393ae5d8c5fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d73c09eb5c4fd7b7fb3cba9a3626f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c70d783302a44a5b2680245b291cfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1500ff9f17954d679982bcea1c70512f",
              "IPY_MODEL_efc209d3d67a42e98cac35cdec14d8c0",
              "IPY_MODEL_c82ee813592c46138e327671fff5fc86"
            ],
            "layout": "IPY_MODEL_859a2e5c8d6e4837a87223f227927445"
          }
        },
        "1500ff9f17954d679982bcea1c70512f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca1954bc5acf46598bf0443656066bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_d1458232fd914d40a661c06724b0ec56",
            "value": "generation_config.json: 100%"
          }
        },
        "efc209d3d67a42e98cac35cdec14d8c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734160c9cd474541837ac775c0b670de",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f572a726cf2454895584ae5e915b880",
            "value": 124
          }
        },
        "c82ee813592c46138e327671fff5fc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6a9b1a672f456591f725d2a1bc0df4",
            "placeholder": "​",
            "style": "IPY_MODEL_d58e177ca0c64436bc226b64418617ea",
            "value": " 124/124 [00:00&lt;00:00, 9.00kB/s]"
          }
        },
        "859a2e5c8d6e4837a87223f227927445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1954bc5acf46598bf0443656066bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1458232fd914d40a661c06724b0ec56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "734160c9cd474541837ac775c0b670de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f572a726cf2454895584ae5e915b880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a6a9b1a672f456591f725d2a1bc0df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58e177ca0c64436bc226b64418617ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "934497e7448f4356a049a546760e3970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b556b8df1ce541ba9fb1b226261a8af1",
              "IPY_MODEL_5f58caaf1e5e4da08510d4f9e1c8d701",
              "IPY_MODEL_493b446daaaa40ca8ed66a6a1d11323a"
            ],
            "layout": "IPY_MODEL_f5008fba1dff4710ad3c45f5bf452607"
          }
        },
        "b556b8df1ce541ba9fb1b226261a8af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07f13a7a59b4eb0a15181418731f274",
            "placeholder": "​",
            "style": "IPY_MODEL_12c17c26642d4a3abb26e43fe21c6555",
            "value": "vocab.json: 100%"
          }
        },
        "5f58caaf1e5e4da08510d4f9e1c8d701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ced02e309e84e52a04419dda8a3dc53",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3745122864f345df90dc69ab2a8a6130",
            "value": 1042301
          }
        },
        "493b446daaaa40ca8ed66a6a1d11323a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_585a99b2c1a148989feb988ba241f4bf",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0e30c50f9b433fa09d71a090d35fad",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.42MB/s]"
          }
        },
        "f5008fba1dff4710ad3c45f5bf452607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f07f13a7a59b4eb0a15181418731f274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c17c26642d4a3abb26e43fe21c6555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ced02e309e84e52a04419dda8a3dc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3745122864f345df90dc69ab2a8a6130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "585a99b2c1a148989feb988ba241f4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0e30c50f9b433fa09d71a090d35fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "613db19804584537b19627866d3f1800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0076e19167564aeb8e23cdbc0144e035",
              "IPY_MODEL_43e7b9e44fd84457a614b4a4b3d81af4",
              "IPY_MODEL_16ffc549b54f4371b6c0dc39868edc36"
            ],
            "layout": "IPY_MODEL_116a8d93c7194f86820d85abeebe767f"
          }
        },
        "0076e19167564aeb8e23cdbc0144e035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0eb144921724e9e8b6b06489515d88a",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8a8b59d87240acb8bb8e333105222d",
            "value": "merges.txt: 100%"
          }
        },
        "43e7b9e44fd84457a614b4a4b3d81af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_056de61f68954b72b8cad3b86055b5e4",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ec14a8f30c84f03bdd0346102e32f0e",
            "value": 456318
          }
        },
        "16ffc549b54f4371b6c0dc39868edc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f74ef6081ee404db2aa4ce6357fd803",
            "placeholder": "​",
            "style": "IPY_MODEL_39ab433a78dd4024a32e0a430a5575e9",
            "value": " 456k/456k [00:00&lt;00:00, 21.8MB/s]"
          }
        },
        "116a8d93c7194f86820d85abeebe767f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0eb144921724e9e8b6b06489515d88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8a8b59d87240acb8bb8e333105222d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "056de61f68954b72b8cad3b86055b5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec14a8f30c84f03bdd0346102e32f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f74ef6081ee404db2aa4ce6357fd803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ab433a78dd4024a32e0a430a5575e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7817d85de364a518c0ffe4ce081a87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e5dffde591d4a5d9b41b5de5e840c82",
              "IPY_MODEL_602e2e2689224c25badfcb11bc2d0aa3",
              "IPY_MODEL_6119f2b2f2f743cf819f8fb80bbc26ad"
            ],
            "layout": "IPY_MODEL_1c6d2694e0b346d0891f20badc9e4b89"
          }
        },
        "8e5dffde591d4a5d9b41b5de5e840c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce0b500270f42a199859fa7ed1e274a",
            "placeholder": "​",
            "style": "IPY_MODEL_5a0ec4f4a623482983b4b79684d4c117",
            "value": "tokenizer.json: 100%"
          }
        },
        "602e2e2689224c25badfcb11bc2d0aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf6541354544aeb928422dfc9cdab73",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9b8a185dba74b87aeaec502e69ab273",
            "value": 1355256
          }
        },
        "6119f2b2f2f743cf819f8fb80bbc26ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a25e1b777c411ab7c181cd5fe62014",
            "placeholder": "​",
            "style": "IPY_MODEL_1fb8db38c127427299d0310e5609e1e8",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 32.1MB/s]"
          }
        },
        "1c6d2694e0b346d0891f20badc9e4b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce0b500270f42a199859fa7ed1e274a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0ec4f4a623482983b4b79684d4c117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf6541354544aeb928422dfc9cdab73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b8a185dba74b87aeaec502e69ab273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8a25e1b777c411ab7c181cd5fe62014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb8db38c127427299d0310e5609e1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a4166547884e6b9847ff004ce8b322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de12a8aa21b74319aa627463324082fb",
              "IPY_MODEL_2f1820f3b84c4824898f01eabbddddc3",
              "IPY_MODEL_c3123af8d4d44ed1ba9c6fa18950bf06"
            ],
            "layout": "IPY_MODEL_d1f7c53d8a934564b4af06b979e93bd5"
          }
        },
        "de12a8aa21b74319aa627463324082fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4f2d0981a648d4a4494ecc712c9a1f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce63efcda42f4087a69706083adf82f8",
            "value": "100%"
          }
        },
        "2f1820f3b84c4824898f01eabbddddc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3282e79feef4817b93800c4b04bf427",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79c09fcc9b1345ffa097e51b1ab03452",
            "value": 100
          }
        },
        "c3123af8d4d44ed1ba9c6fa18950bf06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708466e0ba514ee49136c55c9dddc59d",
            "placeholder": "​",
            "style": "IPY_MODEL_3dcc9f21d39e49b3a81a14c85d692689",
            "value": " 100/100 [00:03&lt;00:00, 24.62it/s]"
          }
        },
        "d1f7c53d8a934564b4af06b979e93bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e4f2d0981a648d4a4494ecc712c9a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce63efcda42f4087a69706083adf82f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3282e79feef4817b93800c4b04bf427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c09fcc9b1345ffa097e51b1ab03452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "708466e0ba514ee49136c55c9dddc59d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcc9f21d39e49b3a81a14c85d692689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}